{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10cf4612",
   "metadata": {},
   "outputs": [],
   "source": [
    "muckrock_api = 'https://www.muckrock.com/api_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cb00ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [404]>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(\n",
    "    muckrock_api + '/api/token',    \n",
    "    data={'username': 'alex2awesome', 'password': 'Pica_pic0'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8343b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "api_token = '0dfe34a351cff64ab5023ad3524076bdce5f1b27'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7708bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headers(token=None):\n",
    "    if token:\n",
    "        return {\n",
    "            'Authorization': 'Token %s' % token,\n",
    "            'content-type': 'application/json'\n",
    "        }\n",
    "    else:\n",
    "        return {'content-type': 'application/json'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "816d46a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = get_headers(token=api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac184a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9010faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "43bade5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [429]>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(api_domain + '/api/token', data={\n",
    "    'username': 'alex2awesome',\n",
    "    'password': 'Pica_pic0'\n",
    "}, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "11009b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_domain = 'https://api.www.documentcloud.org'\n",
    "all_projects = []\n",
    "\n",
    "next_api = api_domain + '/api/projects'\n",
    "\n",
    "# 'agenda-watch-bay-area-le-202027'\n",
    "\n",
    "params = {\n",
    "    'slug': 'agenda-watch', \n",
    "#     'user': ' Chris Stock',\n",
    "#     'created_at': '2021-03-03'\n",
    "}\n",
    "\n",
    "curr_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "13873704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 0...\n"
     ]
    }
   ],
   "source": [
    "while next_api:\n",
    "    if curr_idx % 50 == 0:\n",
    "        print(f'at {curr_idx}...')\n",
    "        \n",
    "    projects = requests.get(next_api, headers=headers, params=params)\n",
    "    res_json = projects.json()\n",
    "    all_projects += res_json['results']\n",
    "    next_api = res_json['next']\n",
    "    curr_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "75c6262a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'next': None,\n",
       " 'previous': None,\n",
       " 'results': [{'id': 210268,\n",
       "   'created_at': '2022-10-24T15:11:46.429953Z',\n",
       "   'description': '',\n",
       "   'edit_access': False,\n",
       "   'add_remove_access': False,\n",
       "   'private': False,\n",
       "   'slug': 'agenda-watch',\n",
       "   'title': 'Agenda Watch',\n",
       "   'updated_at': '2022-10-24T15:11:46.430915Z',\n",
       "   'user': 20993}]}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7bcd1fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = '202027'\n",
    "end_point = f'/api/projects/{project_id}/documents/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "573ae7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(api_domain + end_point,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eb17fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.www.documentcloud.org/api/projects/agenda-watch-bay-area-le-202027/documents/'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_domain + end_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a0913b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Authorization': 'Token 0dfe34a351cff64ab5023ad3524076bdce5f1b27',\n",
       " 'content-type': 'application/json'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742007e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26ecf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb98d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38e8f0f8",
   "metadata": {},
   "source": [
    "# Use Document Cloud Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2e5192a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meeting Minutes\n",
      "City of Oakland Office of the City Clerk\n",
      "Oakland City Hall\n",
      "1 Frank H. Ogawa Plaza\n",
      "Oakland, California 94612\n",
      "LaTonda Simmons, City Clerk\n",
      "Office of the Mayor Annual Recess Agenda\n",
      "August 1, 2007 - September 4, 2007\n",
      "Oakland City Hall, 1 Frank H. Ogawa Plaza, Oakland, California, 94612\n",
      "City of Oakland Website: http://www.oaklandnet.com\n",
      "Tuesday, August 28, 2007 8:30 AM Oakland City Hall - 3rd Floor\n",
      "1 Subject: 2007-2008 Real And Personal Property Tax\n",
      "From: Finance And Management Agency\n",
      "Recommendation: Adopt A Resolution Fixing The Rate Of Property Tax And Levying A Tax On \n",
      "Real And Personal Property In The City Of Oakland For Fiscal Year 2007-2008 For \n",
      "Voter-Approved Indebtedness\n",
      "07-0509\n",
      "Adopted\n",
      "View Report.pdf\n",
      "80794 CMS.pdf\n",
      "2 Subject: McKillop Roadway - Landslide Damage\n",
      "From: Public Works Agency\n",
      "Recommendation: Adopt A Resolution Renewing And Continuing The Local Emergency Due To \n",
      "Landslide Damage To McKillop Roadway First Proclaimed By The City Of Oakland On October \n",
      "17, 2006\n",
      "07-0510\n",
      "Adopted\n",
      "View Report.pdf\n",
      "80795 CMS.pdf\n",
      "City Clerk and Clerk of the Council\n",
      "City of Oakland Page 1 Printed on 2/15/08\u0000\n"
     ]
    }
   ],
   "source": [
    "print(doc_list[0].full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3915689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dfe88aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb20e52c4724510ac695cf41503236b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1073 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from documentcloud import DocumentCloud\n",
    "\n",
    "USERNAME = 'alex2awesome'\n",
    "PASSWORD = 'Pica_pic0'\n",
    "project_id = '202027'\n",
    "\n",
    "client = DocumentCloud(USERNAME, PASSWORD)\n",
    "\n",
    "project = client.projects.get(project_id)\n",
    "doc_list = project.document_list\n",
    "output = []\n",
    "for doc in tqdm(doc_list):\n",
    "    document = doc.data\n",
    "    document['text'] = doc.full_text\n",
    "    output.append(document)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c6528246",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(output).applymap(lambda x: x[0] if isinstance(x, list) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9bad3cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv('../data/agenda-watch-bay-area-202027.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6000c2da",
   "metadata": {},
   "source": [
    "# Use Multinomial HMM for Discourse Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94ed10d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tok = AutoTokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42500bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7c63b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../scripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47d6deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hmm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2873c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0f79724a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "output_df = pd.read_csv('../data/agenda-watch-bay-area-202027.csv')\n",
    "sentences = output_df['text'].str.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40236093",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens = sentences.apply(lambda x: list(map(tok.encode, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6504a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_list_to_array(tok_list, vocab_size):\n",
    "    output = np.zeros(vocab_size)\n",
    "    for tok in tok_list:\n",
    "        output[tok] += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80ff441a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbabea91305245eda3825237de47c477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1073 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_size = len(tok.vocab)\n",
    "doc_lengths = []\n",
    "X = []\n",
    "for doc in tqdm(text_tokens):\n",
    "    doc_lengths.append(len(doc))\n",
    "    for sent in doc:\n",
    "        sent_arr = tok_list_to_array(sent, vocab_size)\n",
    "        X.append(sent_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4e4bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack(X).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f28a1d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c5fd63c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    }
   ],
   "source": [
    "# Set up model\n",
    "model = hmm_test.SentenceMultinomialHMM(\n",
    "    n_components=10,\n",
    "    n_iter=50,\n",
    "    init_params='ste'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1254f04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(data, doc_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "logprob, received = model.decode(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ad950",
   "metadata": {},
   "source": [
    "# Use HMM With Averaged BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "286a1794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from hmmlearn import vhmm, hmm\n",
    "import pickle\n",
    "from transformers import pipeline\n",
    "extractor = pipeline(model=\"huawei-noah/TinyBERT_General_4L_312D\", task=\"feature-extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d4aa5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "output_df = pd.read_csv('../data/agenda-watch-bay-area-202027.csv')\n",
    "sentences = output_df['text'].str.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "53de0c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1d3a43705248f38470d43541059023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1073 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_sent_embeddings = []\n",
    "doc_lengths = []\n",
    "for doc in tqdm(sentences):\n",
    "    doc_lengths.append(len(doc))\n",
    "    \n",
    "    continue\n",
    "    \n",
    "    for sent in doc:\n",
    "        result = extractor(sent, return_tensors=True)\n",
    "        sent_emb = np.array(result[0]).mean(axis=0)\n",
    "        doc_sent_embeddings.append(sent_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "21703fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cache/agenda-watch-embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(doc_sent_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec7038af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cache/agenda-watch-embeddings.pkl', 'rb') as f:\n",
    "    doc_sent_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "206a212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79d529a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalGaussianHMMWithTQDM(vhmm.VariationalGaussianHMM):\n",
    "    def fit(self, X, lengths=None):\n",
    "        X = check_array(X)\n",
    "        if lengths is None:\n",
    "            lengths = np.asarray([X.shape[0]])\n",
    "        self._init(X, lengths)\n",
    "        self._check()\n",
    "        self.monitor_._reset()\n",
    "        for iter in tqdm(range(self.n_iter)):\n",
    "            stats, curr_logprob = self._do_estep(X, lengths)\n",
    "            lower_bound = self._compute_lower_bound(curr_logprob)\n",
    "            self._do_mstep(stats)\n",
    "            self.monitor_.report(lower_bound)\n",
    "            if self.monitor_.converged:\n",
    "                break\n",
    "\n",
    "            if (self.transmat_.sum(axis=1) == 0).any():\n",
    "                _log.warning(\"Some rows of transmat_ have zero sum because no \"\n",
    "                             \"transition from the state was ever observed.\")\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bfd492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "91e7b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VariationalGaussianHMMWithTQDM(\n",
    "     n_components=5,\n",
    "     n_iter=50,\n",
    "#      covariance_type=\"full\",\n",
    "#      implementation=\"scaling\",\n",
    "#      tol=1e-6,\n",
    "     verbose=True\n",
    ")\n",
    "\n",
    "if False:\n",
    "    model = hmm.GaussianHMM(\n",
    "         n_components=5,\n",
    "         n_iter=50,\n",
    "    #      covariance_type=\"full\",\n",
    "         implementation=\"scaling\",\n",
    "    #      tol=1e-6,\n",
    "         verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb6a507",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_docs = None\n",
    "model.fit(data[:sum(doc_lengths[:n_docs])], doc_lengths[:n_docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7443c20",
   "metadata": {},
   "source": [
    "# Try Clustering with KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a9c67954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from more_itertools import flatten\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3f2ce672",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7e28ecba",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = kmeans.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "90053810",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df = pd.Series(list(flatten(sentences))).to_frame('sents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b92c4e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fbbe0d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oakland, California 94612                                                 175\n",
       "San Francisco, CA 94102-4689                                              160\n",
       "10:00 AM                                                                  107\n",
       "San Francisco, CA 94105                                                    54\n",
       "1:00 PM                                                                    50\n",
       "                                                                         ... \n",
       "TUESDAY, JANUARY 16, 2018â 6:15 P.M.                                      1\n",
       "City and County of San Francisco Page 1 Printed at 1:34 pm on 12/24/12      1\n",
       "991909                                                                      1\n",
       "991908                                                                      1\n",
       "City of Sunnyvale Page 1 Printed on 1/16/2020                               1\n",
       "Name: sents, Length: 5280, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df.loc[lambda df: df['cluster'] == 4]['sents'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016de1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10818c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c875f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3234c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c5608b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5247292e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e78b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ab76262",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f172427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2counts(sentence):\n",
    "    ans = []\n",
    "    for word, idx in vocab2id.items():\n",
    "        count = sentence.count(word)\n",
    "        ans.append(count)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4765a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "\n",
    "# For this example, we will model the stages of a conversation,\n",
    "# where each sentence is \"generated\" with an underlying topic, \"cat\" or \"dog\"\n",
    "states = [\"cat\", \"dog\"]\n",
    "id2topic = dict(zip(range(len(states)), states))\n",
    "# we are more likely to talk about cats first\n",
    "start_probs = np.array([0.6, 0.4])\n",
    "\n",
    "# For each topic, the probability of saying certain words can be modeled by\n",
    "# a distribution over vocabulary associated with the categories\n",
    "\n",
    "vocabulary = [\"tail\", \"fetch\", \"mouse\", \"food\"]\n",
    "# if the topic is \"cat\", we are more likely to talk about \"mouse\"\n",
    "# if the topic is \"dog\", we are more likely to talk about \"fetch\"\n",
    "emission_probs = np.array([[0.25, 0.1, 0.4, 0.25],\n",
    "                           [0.2, 0.5, 0.1, 0.2]])\n",
    "\n",
    "# Also assume it's more likely to stay in a state than transition to the other\n",
    "trans_mat = np.array([[0.8, 0.2], [0.2, 0.8]])\n",
    "\n",
    "# Pretend that every sentence we speak only has a total of 5 words,\n",
    "# i.e. we independently utter a word from the vocabulary 5 times per sentence\n",
    "# we observe the following bag of words (BoW) for 8 sentences:\n",
    "observations = [\n",
    "    [\"tail\", \"mouse\", \"mouse\", \"food\", \"mouse\"],\n",
    "    [\"food\", \"mouse\", \"mouse\", \"food\", \"mouse\"],\n",
    "    [\"tail\", \"mouse\", \"mouse\", \"tail\", \"mouse\"],\n",
    "    [\"food\", \"mouse\", \"food\", \"food\", \"tail\"],\n",
    "    [\"tail\", \"fetch\", \"mouse\", \"food\", \"tail\"],\n",
    "    [\"tail\", \"fetch\", \"fetch\", \"food\", \"fetch\"],\n",
    "    [\"fetch\", \"fetch\", \"fetch\", \"food\", \"tail\"],\n",
    "    [\"food\", \"mouse\", \"food\", \"food\", \"tail\"],\n",
    "    [\"tail\", \"mouse\", \"mouse\", \"tail\", \"mouse\"],\n",
    "    [\"fetch\", \"fetch\", \"fetch\", \"fetch\", \"fetch\", \"fetch\"]\n",
    "]\n",
    "\n",
    "# Convert \"sentences\" to numbers:\n",
    "vocab2id = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "X = []\n",
    "for sentence in observations:\n",
    "    row = sentence2counts(sentence)\n",
    "    X.append(row)\n",
    "\n",
    "data = np.array(X, dtype=int)\n",
    "\n",
    "# pretend this is repeated, so we have more data to learn from:\n",
    "lengths = [len(X)]*5\n",
    "sequences = np.tile(data, (5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "58392b27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceMultinomialHMM2(n_components=2, n_iter=50,\n",
       "                        random_state=RandomState(MT19937) at 0x7F85A9DCF740)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up model:\n",
    "model = SentenceMultinomialHMM2(\n",
    "    n_components=len(states),\n",
    "    n_iter=50,\n",
    "    init_params='ste'\n",
    ")\n",
    "\n",
    "model.fit(sequences, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0d3ebcb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Even though the 'startprob_' attribute is set, it will be overwritten during initialization because 'init_params' contains 's'\n",
      "Even though the 'transmat_' attribute is set, it will be overwritten during initialization because 'init_params' contains 't'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics discussed:\n",
      "['cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat', 'dog']\n",
      "Learned emission probs:\n",
      "[[2.57134386e-01 2.86295346e-02 4.28529613e-01 2.85706466e-01]\n",
      " [1.24992633e-01 7.50014271e-01 7.48807992e-06 1.24985608e-01]]\n",
      "Learned transition matrix:\n",
      "[[0.71431126 0.28568874]\n",
      " [0.50015702 0.49984298]]\n"
     ]
    }
   ],
   "source": [
    "model.fit(sequences, lengths)\n",
    "logprob, received = model.decode(sequences)\n",
    "\n",
    "print(\"Topics discussed:\")\n",
    "print([id2topic[x] for x in received])\n",
    "\n",
    "print(\"Learned emission probs:\")\n",
    "print(model.emissionprob_)\n",
    "\n",
    "print(\"Learned transition matrix:\")\n",
    "print(model.transmat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d6df0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81208c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e52c123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff599f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50dee45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
